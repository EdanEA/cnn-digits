{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "11c47e8a-558e-463d-8009-0a5b01a75d51",
   "metadata": {
    "id": "11c47e8a-558e-463d-8009-0a5b01a75d51"
   },
   "source": [
    "# 0-9 Digit Convolutional Neural Network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecdf3a36-9011-4bae-9909-9e087b3fca43",
   "metadata": {
    "id": "ecdf3a36-9011-4bae-9909-9e087b3fca43"
   },
   "source": [
    "## Building dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed755db1-5482-4b05-ad4f-7470cfc11991",
   "metadata": {
    "id": "ed755db1-5482-4b05-ad4f-7470cfc11991"
   },
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecac8c36-2895-4ef1-bc6d-b2f6f0c0ead9",
   "metadata": {
    "id": "ecac8c36-2895-4ef1-bc6d-b2f6f0c0ead9"
   },
   "outputs": [],
   "source": [
    "!pip install pillow\n",
    "!pip install tensorflow\n",
    "!pip install numpy\n",
    "!pip install scikit-learn\n",
    "!pip install matplotlib\n",
    "!pip install visualkeras\n",
    "!pip install scikit-image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4850164b-8dde-49f8-836d-6c7b6aa7a1c3",
   "metadata": {
    "id": "4850164b-8dde-49f8-836d-6c7b6aa7a1c3"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import tarfile\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b203fb33-c411-45cf-a285-b20f6788fa87",
   "metadata": {
    "id": "b203fb33-c411-45cf-a285-b20f6788fa87"
   },
   "source": [
    "### Untar dataset archive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c618c189-e059-4da9-b920-9c785c0df5c3",
   "metadata": {
    "id": "c618c189-e059-4da9-b920-9c785c0df5c3"
   },
   "outputs": [],
   "source": [
    "if not os.path.isdir('./numbers/'):\n",
    "    with tarfile.open('numbers.tar.xz') as f:\n",
    "        f.extractall('.')\n",
    "else:\n",
    "    print('Already untarred')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10157dd9-a6cb-4a9d-8320-b14c2040abb5",
   "metadata": {
    "id": "10157dd9-a6cb-4a9d-8320-b14c2040abb5"
   },
   "source": [
    "### Creating training and testing datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b471b661-8453-4c5a-9975-5f1d38eca371",
   "metadata": {
    "id": "b471b661-8453-4c5a-9975-5f1d38eca371"
   },
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rescale = 1./255,\n",
    "    shear_range = 0.2,\n",
    "    zoom_range = 0.2,\n",
    "    horizontal_flip = True,\n",
    "    validation_split = 0.2\n",
    ")\n",
    "\n",
    "train_dataset = datagen.flow_from_directory(\n",
    "    'numbers',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'training'\n",
    ")\n",
    "\n",
    "test_dataset = datagen.flow_from_directory(\n",
    "    'numbers',\n",
    "    target_size = (64, 64),\n",
    "    batch_size = 128,\n",
    "    class_mode = 'categorical',\n",
    "    subset = 'validation'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "abe62d37-526d-41b0-87b8-ac97083c90b5",
   "metadata": {
    "id": "abe62d37-526d-41b0-87b8-ac97083c90b5"
   },
   "outputs": [],
   "source": [
    "print(len(train_dataset))\n",
    "print(len(test_dataset))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2748474-08f3-4fce-a1c0-0ca10827a48c",
   "metadata": {
    "id": "b2748474-08f3-4fce-a1c0-0ca10827a48c"
   },
   "source": [
    "## Creating convolutional neural network"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "547de1ef-0621-4d1d-a3a0-7f0e564b5e4e",
   "metadata": {
    "id": "547de1ef-0621-4d1d-a3a0-7f0e564b5e4e"
   },
   "source": [
    "### Initialize network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f41ea70-8995-4edb-8b14-781eca88a0b5",
   "metadata": {
    "id": "1f41ea70-8995-4edb-8b14-781eca88a0b5"
   },
   "outputs": [],
   "source": [
    "cnn = tf.keras.Sequential()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c85385c-63df-468a-a3c5-4f7fc57b6221",
   "metadata": {
    "id": "3c85385c-63df-468a-a3c5-4f7fc57b6221"
   },
   "source": [
    "### Setup layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11184fff-9499-4809-a8ee-31de6309e516",
   "metadata": {
    "id": "11184fff-9499-4809-a8ee-31de6309e516"
   },
   "outputs": [],
   "source": [
    "cnn.add(tf.keras.Input(shape = (64, 64, 3)))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(32, (3, 3), activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Conv2D(64, (3, 3), activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.MaxPooling2D((2, 2)))\n",
    "cnn.add(tf.keras.layers.Dropout(0.2))\n",
    "\n",
    "cnn.add(tf.keras.layers.Flatten())\n",
    "cnn.add(tf.keras.layers.Dense(128, activation = 'relu'))\n",
    "cnn.add(tf.keras.layers.Dense(10, activation = 'softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1aca228a-bdf7-4424-91b7-844a68c4eb06",
   "metadata": {
    "id": "1aca228a-bdf7-4424-91b7-844a68c4eb06"
   },
   "source": [
    "### Compile CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfdaef3a-e776-439c-bd41-f786a6a8c12a",
   "metadata": {
    "id": "cfdaef3a-e776-439c-bd41-f786a6a8c12a"
   },
   "outputs": [],
   "source": [
    "cnn.compile(\n",
    "    optimizer = tf.keras.optimizers.Adam(weight_decay = 0.01),\n",
    "    loss = tf.keras.losses.CategoricalCrossentropy(),\n",
    "    metrics = [ tf.keras.metrics.CategoricalAccuracy(), tf.keras.metrics.Precision(), tf.keras.metrics.Recall() ]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ffd8a1a-ef80-4910-8380-ea5157958ad4",
   "metadata": {
    "id": "3ffd8a1a-ef80-4910-8380-ea5157958ad4"
   },
   "source": [
    "### Train CNN on dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4658d536-2122-4e54-b576-6b6401f50109",
   "metadata": {
    "id": "4658d536-2122-4e54-b576-6b6401f50109"
   },
   "outputs": [],
   "source": [
    "cnn.fit(x = train_dataset, validation_data = test_dataset, epochs = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2bac652-dbef-4a10-be28-e5c9d0da6768",
   "metadata": {
    "id": "b2bac652-dbef-4a10-be28-e5c9d0da6768"
   },
   "source": [
    "## Testing model accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f1e1d49-1f58-4c90-aede-a43a4991992a",
   "metadata": {},
   "source": [
    "### Load model (uncomment if not wanting to train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7110ca95-bf05-4186-97ed-5a2543b30b9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# cnn = tf.keras.models.load_model('model.h5')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fa5dd1b-564d-4e34-8be9-533e747e5be3",
   "metadata": {
    "id": "8fa5dd1b-564d-4e34-8be9-533e747e5be3"
   },
   "source": [
    "### Show that model works on an individual image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "382569e5-6152-4bff-84ea-fb968fab02e7",
   "metadata": {
    "id": "382569e5-6152-4bff-84ea-fb968fab02e7"
   },
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing import image\n",
    "\n",
    "test_image = image.load_img('numbers/7/384.png', target_size = (64, 64))\n",
    "display(test_image)\n",
    "test_image = image.img_to_array(test_image)\n",
    "test_image = np.expand_dims(test_image, axis = 0)\n",
    "test_image /= 255\n",
    "\n",
    "cnn.predict(test_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d871ade-4780-494b-92b5-6cdad1051ee0",
   "metadata": {
    "id": "7d871ade-4780-494b-92b5-6cdad1051ee0"
   },
   "source": [
    "### Get expected and predicted categories for test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03a3ecc3-5e6f-4e24-aadb-e7f6703df91e",
   "metadata": {
    "id": "03a3ecc3-5e6f-4e24-aadb-e7f6703df91e"
   },
   "outputs": [],
   "source": [
    "expected_vals = []\n",
    "predicted_vals = []\n",
    "for i in range(len(test_dataset)):\n",
    "    predicted_vals = np.concatenate((predicted_vals, cnn.predict(test_dataset[i]).argmax(axis = 1)))\n",
    "    for j in range(len(test_dataset[i][1])):\n",
    "        expected_vals.append(test_dataset[i][1][j].argmax(axis = 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c8f950-21d9-4127-a058-9427b9f8a528",
   "metadata": {
    "id": "e0c8f950-21d9-4127-a058-9427b9f8a528"
   },
   "outputs": [],
   "source": [
    "print(len(expected_vals))\n",
    "print(len(predicted_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95103dc3-7623-426f-bd9a-fcdfb05d7426",
   "metadata": {
    "id": "95103dc3-7623-426f-bd9a-fcdfb05d7426"
   },
   "source": [
    "### Generate confusion matrix graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032f2dbd-9c83-4ac0-9504-730aaeda5935",
   "metadata": {
    "id": "032f2dbd-9c83-4ac0-9504-730aaeda5935"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, f1_score\n",
    "cmd = ConfusionMatrixDisplay(confusion_matrix(expected_vals, predicted_vals))\n",
    "cmd.plot(cmap = 'viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a1ff809-bb9c-408e-9bef-80dfbe5f93b1",
   "metadata": {
    "id": "5a1ff809-bb9c-408e-9bef-80dfbe5f93b1"
   },
   "source": [
    "### Get calculated F1 score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "678eae84-4743-417c-bc54-ac5c0696d680",
   "metadata": {
    "id": "678eae84-4743-417c-bc54-ac5c0696d680"
   },
   "outputs": [],
   "source": [
    "f1_score(expected_vals, predicted_vals, average = 'macro')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cee10da6-4916-442c-a627-8a046082dfdf",
   "metadata": {
    "id": "cee10da6-4916-442c-a627-8a046082dfdf"
   },
   "source": [
    "## Visualizing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7394797f-c13f-45bd-b67e-64b4fdddea3d",
   "metadata": {
    "id": "7394797f-c13f-45bd-b67e-64b4fdddea3d"
   },
   "source": [
    "### Table summary of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9682d55-f9d4-49f1-aea7-6c05998b22db",
   "metadata": {
    "id": "e9682d55-f9d4-49f1-aea7-6c05998b22db"
   },
   "outputs": [],
   "source": [
    "print(cnn.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd7ac49e-9380-45a1-85f9-211b855da5ce",
   "metadata": {
    "id": "cd7ac49e-9380-45a1-85f9-211b855da5ce"
   },
   "source": [
    "### Diagrams of model architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e443fe33-32c1-4987-a392-3827088ac078",
   "metadata": {
    "id": "e443fe33-32c1-4987-a392-3827088ac078"
   },
   "outputs": [],
   "source": [
    "import visualkeras\n",
    "display(visualkeras.layered_view(cnn, legend = True, show_dimension = True))\n",
    "display(visualkeras.graph_view(cnn))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc4537cc-af3b-4ff4-aa48-abdc03505950",
   "metadata": {
    "id": "cc4537cc-af3b-4ff4-aa48-abdc03505950"
   },
   "source": [
    "### Visualizing effects of layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44035a24-e456-4803-9821-a8dbffa42050",
   "metadata": {
    "id": "44035a24-e456-4803-9821-a8dbffa42050"
   },
   "outputs": [],
   "source": [
    "grad_model = tf.keras.models.Model(\n",
    "    [cnn.inputs],\n",
    "    [cnn.get_layer('conv2d_1').output,\n",
    "    cnn.get_layer('dense_1').output]\n",
    ")\n",
    "\n",
    "# code originally from https://stackoverflow.com/questions/63287641/get-each-layer-output-in-keras-model-for-a-single-image\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras.preprocessing.image import img_to_array, load_img\n",
    "\n",
    "layer_outputs = [layer.output for layer in grad_model.layers[1:]]\n",
    "visual_model = tf.keras.models.Model(inputs = grad_model.input, outputs = layer_outputs)\n",
    "feature_maps = visual_model.predict(test_image)\n",
    "layer_names = [layer.name for layer in grad_model.layers[1:]]\n",
    "\n",
    "for layer_name, feature_map in zip(layer_names, feature_maps):\n",
    "    if len(feature_map.shape) == 4:\n",
    "        n_features = feature_map.shape[-1]\n",
    "        size = feature_map.shape[1]\n",
    "        display_grid = np.zeros((size, size * n_features))\n",
    "        for i in range(n_features):\n",
    "            x = feature_map[0, :, :, i]\n",
    "            x -= x.mean()\n",
    "            x /= x.std()\n",
    "            x *= 64\n",
    "            x += 128\n",
    "            x = np.clip(x, 0, 255).astype('uint8')\n",
    "            display_grid[:, i * size : (i + 1) * size] = x\n",
    "        scale = 20. / n_features\n",
    "        plt.figure(figsize=(scale * n_features, scale))\n",
    "        plt.title(layer_name)\n",
    "        plt.grid(False)\n",
    "        plt.imshow(display_grid, aspect='auto', cmap='viridis')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9accf5bc-8242-4043-8755-ecfb136cc37c",
   "metadata": {
    "id": "9accf5bc-8242-4043-8755-ecfb136cc37c"
   },
   "source": [
    "## Predicting numbers with more than one digit"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb8abca-0a0c-46af-ae71-78ebd5b1a5f4",
   "metadata": {
    "id": "bfb8abca-0a0c-46af-ae71-78ebd5b1a5f4"
   },
   "source": [
    "### Read image and generate labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1e443db-95ca-43e0-846f-f2db1e7f75ba",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 240
    },
    "id": "b1e443db-95ca-43e0-846f-f2db1e7f75ba",
    "outputId": "e48bc272-2040-43c8-f499-47d22dc12be1"
   },
   "outputs": [],
   "source": [
    "import skimage as ski\n",
    "\n",
    "image = ski.io.imread(\"702.png\")\n",
    "gray = ski.color.rgb2gray(image)\n",
    "label_image = ski.measure.label(gray)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d675e098-2c0b-48a1-ac11-60926d70843e",
   "metadata": {
    "id": "d675e098-2c0b-48a1-ac11-60926d70843e"
   },
   "source": [
    "### Segment image based upon generated labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ac3a6a1-ccd4-4901-a5c4-13339361d8e5",
   "metadata": {
    "id": "3ac3a6a1-ccd4-4901-a5c4-13339361d8e5"
   },
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "segments = []\n",
    "fig, ax = plt.subplots(figsize=(8, 6))\n",
    "ax.imshow(gray, cmap=\"gray\")\n",
    "\n",
    "for region in ski.measure.regionprops(label_image):\n",
    "    minr, minc, maxr, maxc = region.bbox\n",
    "    segmented_digit = gray[minr:maxr, minc:maxc]  # crop the digit\n",
    "    segments.append((minc, segmented_digit))  # store x-position for sorting\n",
    "    rect = plt.Rectangle((minc, minr), maxc - minc, maxr - minr, edgecolor='red', linewidth=2, fill=False) # plot border on base image\n",
    "    ax.add_patch(rect)\n",
    "\n",
    "segments = sorted(segments, key=lambda x: x[0]) # sort so digits are predicted on left-to-right\n",
    "\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WercwRP4BK5S",
   "metadata": {
    "id": "WercwRP4BK5S"
   },
   "source": [
    "### Show images segments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "QrWZiNrOAtyY",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 264
    },
    "id": "QrWZiNrOAtyY",
    "outputId": "2d2f2658-46e3-4c23-9e11-1e312c02d3f0"
   },
   "outputs": [],
   "source": [
    "resized_segments = [ski.transform.resize(seg, (64, 64), anti_aliasing=True) for _, seg in segments]\n",
    "fig, axes = plt.subplots(1, len(resized_segments), figsize=(10, 5))\n",
    "for ax, segment in zip(axes, resized_segments):\n",
    "    ax.imshow(segment, cmap=\"gray\")\n",
    "    ax.axis(\"off\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6778693-df7f-43b7-a54f-92022d0e60fa",
   "metadata": {
    "id": "e6778693-df7f-43b7-a54f-92022d0e60fa"
   },
   "source": [
    "### Iterate through segments and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89b67696-5931-427c-a440-9ee2a86e23d4",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 225
    },
    "id": "89b67696-5931-427c-a440-9ee2a86e23d4",
    "outputId": "1a2bdfa9-9213-40a7-b601-414f0abfb8a0"
   },
   "outputs": [],
   "source": [
    "predicted_vals = []\n",
    "for _, s in segments:\n",
    "    # image to rgb and resize for prediction\n",
    "    s = ski.color.gray2rgb(s)\n",
    "    s = ski.transform.resize(s, (64, 64))\n",
    "    s = np.expand_dims(s, axis = 0)\n",
    "\n",
    "    prediction = cnn.predict(s)\n",
    "    display(prediction)\n",
    "\n",
    "    predicted_vals.append(prediction.argmax())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6008a140-e28a-4474-8d89-f62803031fae",
   "metadata": {
    "id": "6008a140-e28a-4474-8d89-f62803031fae"
   },
   "source": [
    "### Print predicted number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "017a8d52-dba0-44db-b017-5efebb89774e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "017a8d52-dba0-44db-b017-5efebb89774e",
    "outputId": "7e0d7312-0c87-41b8-87c6-066a1d94c6e6"
   },
   "outputs": [],
   "source": [
    "print(\"\".join(str(p) for p in predicted_vals))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9784ac5-246f-43e6-a522-f392dd285c7f",
   "metadata": {
    "id": "f9784ac5-246f-43e6-a522-f392dd285c7f"
   },
   "source": [
    "## Save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "974683ad-9c53-46a0-8cee-bc247854deb6",
   "metadata": {
    "id": "974683ad-9c53-46a0-8cee-bc247854deb6"
   },
   "outputs": [],
   "source": [
    "cnn.save('model.h5')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
